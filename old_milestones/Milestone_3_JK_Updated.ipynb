{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h14o5uwmr9sB",
        "outputId": "8928247b-ff23-46cc-cd41-dcc4f4ea944d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'CSE-151A-Project-'...\n",
            "remote: Enumerating objects: 72, done.\u001b[K\n",
            "remote: Counting objects: 100% (72/72), done.\u001b[K\n",
            "remote: Compressing objects: 100% (65/65), done.\u001b[K\n",
            "remote: Total 72 (delta 29), reused 0 (delta 0), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (72/72), 491.21 KiB | 4.96 MiB/s, done.\n",
            "Resolving deltas: 100% (29/29), done.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/jkaminsky2/CSE-151A-Project-.git"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#!pip install scikeras\n",
        "#!pip install keras_tuner\n",
        "import keras\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import OrdinalEncoder\n",
        "from sklearn.model_selection import RepeatedKFold, cross_validate\n",
        "from scikeras.wrappers import KerasClassifier\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Input\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix\n",
        "from kerastuner.tuners import RandomSearch\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "from sklearn.utils.class_weight import compute_class_weight\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L7tX2TnysAvE",
        "outputId": "fec1d942-09ba-4d20-ac3d-c99bc35a2d51"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-2-52fbe02ef5fb>:15: DeprecationWarning: `import kerastuner` is deprecated, please use `import keras_tuner`.\n",
            "  from kerastuner.tuners import RandomSearch\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "num_df = pd.read_csv(\"CSE-151A-Project-/final_num_df_cse151a.csv\")\n",
        "X = num_df.drop(['Class_$','Class_$$', 'Class_$$$', 'Class_'], axis=1).astype(float)\n",
        "y = num_df[['Class_$$', 'Class_$$$', 'Class_']].astype(float)\n",
        "X = X[['closed', 'location_cluster', 'rating', 'relevant_cat', 'cat_cluster','sentiment']]\n",
        "X['cat_cluster'] += 1\n",
        "X['location_cluster'] = X['location_cluster'].fillna(-1)\n",
        "X['location_cluster'] += 1\n",
        "display(X.shape)\n",
        "display(y.shape)\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)\n",
        "early_stopping = tf.keras.callbacks.EarlyStopping(\n",
        "    monitor='accuracy',\n",
        "    min_delta=0,\n",
        "    patience=10,\n",
        "    verbose=0,\n",
        "    mode='auto',\n",
        "    baseline=None,\n",
        "    restore_best_weights=False,\n",
        "    start_from_epoch=0\n",
        ")\n",
        "\n",
        "a= y_train['Class_$$$'] * 3 + y_train['Class_$$'] * 2 + y_train['Class_']\n",
        "a -= 1\n",
        "class_weights = compute_class_weight(class_weight=\"balanced\", classes=np.unique(a), y=a)\n",
        "class_weight = {0: class_weights[0], 1: class_weights[1], 2: class_weights[2]}\n",
        "\n"
      ],
      "metadata": {
        "id": "K7fgHvwg4uiG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def build_model(hp):\n",
        "    input_layer = Input(shape=6)\n",
        "    x = input_layer\n",
        "\n",
        "    for i in range(4):\n",
        "        units = hp.Int(f'units_{i}', min_value=8, max_value=18, step=4)\n",
        "        activation = hp.Choice(f'activation_{i}', ['relu', 'sigmoid', 'tanh'])\n",
        "        x = Dense(units=units, activation=activation)(x)\n",
        "    output = Dense(units=3, activation='softmax')(x)\n",
        "    model = Model(inputs=input_layer, outputs=output)\n",
        "\n",
        "    lr = hp.Float(\"learning_rate\", min_value=0.0001, max_value=0.3, sampling=\"log\")\n",
        "    epochs = hp.Int('epochs', min_value=50, max_value=200, step=50)\n",
        "\n",
        "    model.compile(optimizer=keras.optimizers.Adam(learning_rate=lr), loss='categorical_focal_crossentropy', metrics=['accuracy'], sample_weight_mode=class_weight)\n",
        "    return model\n",
        "\n",
        "tuner = RandomSearch(\n",
        "    hypermodel=build_model,\n",
        "    objective='accuracy',\n",
        "    max_trials=3,\n",
        "    executions_per_trial=2,\n",
        "    directory='save_directory',\n",
        "    project_name='hyperparams_optimization')\n",
        "\n",
        "tuner.search(X_train, y_train, epochs=100)\n",
        "\n",
        "best_hyperparameters = tuner.get_best_hyperparameters()[0]\n",
        "\n",
        "best_model = tuner.hypermodel.build(best_hyperparameters)\n",
        "\n",
        "best_model.fit(X_train, y_train, epochs=best_hyperparameters['epochs'])\n",
        "\n",
        "y_pred_probabilities = best_model.predict(X_test)\n",
        "y_pred = np.argmax(y_pred_probabilities, axis=1)\n",
        "y_true_expanded = np.argmax(y_test.values, axis=1)\n",
        "test_accuracy = accuracy_score(y_true_expanded, y_pred)\n",
        "\n",
        "print(\"Test Accuracy:\", test_accuracy)\n",
        "print(\"Optimized Hyperparameters\\nNumber of Units in Each Hidden Layer:\", [best_hyperparameters[f'units_{i}'] for i in range(4)])\n",
        "print(\"Activation Function for Each Hidden Layer:\", [best_hyperparameters[f'activation_{i}'] for i in range(4)])\n",
        "print(F\"Learning Rate: {best_hyperparameters['learning_rate']}\\nEpochs: {best_hyperparameters['epochs']}\")\n",
        "\n",
        "from sklearn.metrics import confusion_matrix\n",
        "conf_matrix = confusion_matrix(y_true_expanded, y_pred)\n",
        "print(\"Confusion Matrix:\")\n",
        "print(conf_matrix)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "XtA5wMZNsUXG",
        "outputId": "e5f36609-3c24-4c5b-f178-9fc24ed012b6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trial 3 Complete [00h 00m 39s]\n",
            "accuracy: 0.6375176310539246\n",
            "\n",
            "Best accuracy So Far: 0.6382228434085846\n",
            "Total elapsed time: 00h 01m 23s\n",
            "Epoch 1/150\n",
            "23/23 [==============================] - 2s 2ms/step - loss: 0.1530 - accuracy: 0.0141 \n",
            "Epoch 2/150\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.1471 - accuracy: 0.0141\n",
            "Epoch 3/150\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 0.1423 - accuracy: 0.0169\n",
            "Epoch 4/150\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.1382 - accuracy: 0.0212\n",
            "Epoch 5/150\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.1347 - accuracy: 0.0226\n",
            "Epoch 6/150\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.1319 - accuracy: 0.0282\n",
            "Epoch 7/150\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.1295 - accuracy: 0.0324\n",
            "Epoch 8/150\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.1273 - accuracy: 0.0423\n",
            "Epoch 9/150\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.1252 - accuracy: 0.0733\n",
            "Epoch 10/150\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.1232 - accuracy: 0.1439\n",
            "Epoch 11/150\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.1210 - accuracy: 0.3484\n",
            "Epoch 12/150\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.1180 - accuracy: 0.6319\n",
            "Epoch 13/150\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.1144 - accuracy: 0.6333\n",
            "Epoch 14/150\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.1111 - accuracy: 0.6375\n",
            "Epoch 15/150\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.1080 - accuracy: 0.6375\n",
            "Epoch 16/150\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.1047 - accuracy: 0.6375\n",
            "Epoch 17/150\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.1013 - accuracy: 0.6375\n",
            "Epoch 18/150\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 0.0977 - accuracy: 0.6375\n",
            "Epoch 19/150\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.0943 - accuracy: 0.6375\n",
            "Epoch 20/150\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 0.0910 - accuracy: 0.6375\n",
            "Epoch 21/150\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.0875 - accuracy: 0.6375\n",
            "Epoch 22/150\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.0841 - accuracy: 0.6375\n",
            "Epoch 23/150\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.0808 - accuracy: 0.6375\n",
            "Epoch 24/150\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 0.0778 - accuracy: 0.6375\n",
            "Epoch 25/150\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 0.0750 - accuracy: 0.6375\n",
            "Epoch 26/150\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 0.0724 - accuracy: 0.6375\n",
            "Epoch 27/150\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 0.0699 - accuracy: 0.6375\n",
            "Epoch 28/150\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 0.0677 - accuracy: 0.6375\n",
            "Epoch 29/150\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 0.0659 - accuracy: 0.6375\n",
            "Epoch 30/150\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 0.0643 - accuracy: 0.6375\n",
            "Epoch 31/150\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.0628 - accuracy: 0.6375\n",
            "Epoch 32/150\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 0.0618 - accuracy: 0.6375\n",
            "Epoch 33/150\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 0.0609 - accuracy: 0.6375\n",
            "Epoch 34/150\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 0.0601 - accuracy: 0.6375\n",
            "Epoch 35/150\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.0594 - accuracy: 0.6375\n",
            "Epoch 36/150\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.0589 - accuracy: 0.6375\n",
            "Epoch 37/150\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 0.0584 - accuracy: 0.6375\n",
            "Epoch 38/150\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.0580 - accuracy: 0.6375\n",
            "Epoch 39/150\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.0577 - accuracy: 0.6375\n",
            "Epoch 40/150\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.0574 - accuracy: 0.6375\n",
            "Epoch 41/150\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.0572 - accuracy: 0.6375\n",
            "Epoch 42/150\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.0570 - accuracy: 0.6375\n",
            "Epoch 43/150\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.0568 - accuracy: 0.6375\n",
            "Epoch 44/150\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.0567 - accuracy: 0.6375\n",
            "Epoch 45/150\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.0565 - accuracy: 0.6375\n",
            "Epoch 46/150\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 0.0564 - accuracy: 0.6375\n",
            "Epoch 47/150\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.0563 - accuracy: 0.6375\n",
            "Epoch 48/150\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.0562 - accuracy: 0.6375\n",
            "Epoch 49/150\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.0561 - accuracy: 0.6375\n",
            "Epoch 50/150\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 0.0560 - accuracy: 0.6375\n",
            "Epoch 51/150\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.0560 - accuracy: 0.6361\n",
            "Epoch 52/150\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.0559 - accuracy: 0.6375\n",
            "Epoch 53/150\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.0559 - accuracy: 0.6375\n",
            "Epoch 54/150\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.0559 - accuracy: 0.6347\n",
            "Epoch 55/150\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.0559 - accuracy: 0.6361\n",
            "Epoch 56/150\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.0558 - accuracy: 0.6375\n",
            "Epoch 57/150\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.0558 - accuracy: 0.6375\n",
            "Epoch 58/150\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.0558 - accuracy: 0.6375\n",
            "Epoch 59/150\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.0557 - accuracy: 0.6375\n",
            "Epoch 60/150\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.0557 - accuracy: 0.6375\n",
            "Epoch 61/150\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.0557 - accuracy: 0.6375\n",
            "Epoch 62/150\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.0557 - accuracy: 0.6375\n",
            "Epoch 63/150\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.0557 - accuracy: 0.6375\n",
            "Epoch 64/150\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 0.0557 - accuracy: 0.6389\n",
            "Epoch 65/150\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.0557 - accuracy: 0.6389\n",
            "Epoch 66/150\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.0556 - accuracy: 0.6389\n",
            "Epoch 67/150\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.0556 - accuracy: 0.6375\n",
            "Epoch 68/150\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.0556 - accuracy: 0.6375\n",
            "Epoch 69/150\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.0556 - accuracy: 0.6375\n",
            "Epoch 70/150\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.0556 - accuracy: 0.6375\n",
            "Epoch 71/150\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 0.0556 - accuracy: 0.6389\n",
            "Epoch 72/150\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.0556 - accuracy: 0.6389\n",
            "Epoch 73/150\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.0556 - accuracy: 0.6389\n",
            "Epoch 74/150\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.0555 - accuracy: 0.6389\n",
            "Epoch 75/150\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.0555 - accuracy: 0.6389\n",
            "Epoch 76/150\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.0555 - accuracy: 0.6389\n",
            "Epoch 77/150\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.0555 - accuracy: 0.6403\n",
            "Epoch 78/150\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.0555 - accuracy: 0.6389\n",
            "Epoch 79/150\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 0.0555 - accuracy: 0.6389\n",
            "Epoch 80/150\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.0555 - accuracy: 0.6389\n",
            "Epoch 81/150\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 0.0555 - accuracy: 0.6403\n",
            "Epoch 82/150\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.0555 - accuracy: 0.6403\n",
            "Epoch 83/150\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.0555 - accuracy: 0.6403\n",
            "Epoch 84/150\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.0555 - accuracy: 0.6403\n",
            "Epoch 85/150\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.0554 - accuracy: 0.6403\n",
            "Epoch 86/150\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.0555 - accuracy: 0.6389\n",
            "Epoch 87/150\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.0554 - accuracy: 0.6403\n",
            "Epoch 88/150\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.0554 - accuracy: 0.6403\n",
            "Epoch 89/150\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.0554 - accuracy: 0.6403\n",
            "Epoch 90/150\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.0554 - accuracy: 0.6403\n",
            "Epoch 91/150\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.0554 - accuracy: 0.6403\n",
            "Epoch 92/150\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 0.0554 - accuracy: 0.6403\n",
            "Epoch 93/150\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.0554 - accuracy: 0.6403\n",
            "Epoch 94/150\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 0.0554 - accuracy: 0.6403\n",
            "Epoch 95/150\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.0554 - accuracy: 0.6432\n",
            "Epoch 96/150\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.0554 - accuracy: 0.6389\n",
            "Epoch 97/150\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 0.0554 - accuracy: 0.6403\n",
            "Epoch 98/150\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 0.0554 - accuracy: 0.6403\n",
            "Epoch 99/150\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 0.0554 - accuracy: 0.6403\n",
            "Epoch 100/150\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.0554 - accuracy: 0.6403\n",
            "Epoch 101/150\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.0554 - accuracy: 0.6432\n",
            "Epoch 102/150\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 0.0553 - accuracy: 0.6474\n",
            "Epoch 103/150\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 0.0554 - accuracy: 0.6403\n",
            "Epoch 104/150\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 0.0554 - accuracy: 0.6403\n",
            "Epoch 105/150\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 0.0554 - accuracy: 0.6403\n",
            "Epoch 106/150\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 0.0553 - accuracy: 0.6403\n",
            "Epoch 107/150\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 0.0553 - accuracy: 0.6403\n",
            "Epoch 108/150\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 0.0553 - accuracy: 0.6403\n",
            "Epoch 109/150\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 0.0553 - accuracy: 0.6516\n",
            "Epoch 110/150\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 0.0553 - accuracy: 0.6502\n",
            "Epoch 111/150\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 0.0553 - accuracy: 0.6432\n",
            "Epoch 112/150\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 0.0553 - accuracy: 0.6432\n",
            "Epoch 113/150\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.0553 - accuracy: 0.6530\n",
            "Epoch 114/150\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.0553 - accuracy: 0.6488\n",
            "Epoch 115/150\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.0553 - accuracy: 0.6516\n",
            "Epoch 116/150\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.0553 - accuracy: 0.6516\n",
            "Epoch 117/150\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.0553 - accuracy: 0.6516\n",
            "Epoch 118/150\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.0553 - accuracy: 0.6488\n",
            "Epoch 119/150\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.0552 - accuracy: 0.6530\n",
            "Epoch 120/150\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.0552 - accuracy: 0.6516\n",
            "Epoch 121/150\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.0552 - accuracy: 0.6502\n",
            "Epoch 122/150\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.0552 - accuracy: 0.6573\n",
            "Epoch 123/150\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 0.0552 - accuracy: 0.6516\n",
            "Epoch 124/150\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 0.0552 - accuracy: 0.6502\n",
            "Epoch 125/150\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 0.0552 - accuracy: 0.6474\n",
            "Epoch 126/150\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.0552 - accuracy: 0.6516\n",
            "Epoch 127/150\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.0552 - accuracy: 0.6516\n",
            "Epoch 128/150\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.0552 - accuracy: 0.6559\n",
            "Epoch 129/150\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.0552 - accuracy: 0.6530\n",
            "Epoch 130/150\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.0552 - accuracy: 0.6544\n",
            "Epoch 131/150\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.0552 - accuracy: 0.6530\n",
            "Epoch 132/150\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.0552 - accuracy: 0.6544\n",
            "Epoch 133/150\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.0552 - accuracy: 0.6544\n",
            "Epoch 134/150\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.0552 - accuracy: 0.6530\n",
            "Epoch 135/150\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.0552 - accuracy: 0.6544\n",
            "Epoch 136/150\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.0552 - accuracy: 0.6530\n",
            "Epoch 137/150\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.0552 - accuracy: 0.6530\n",
            "Epoch 138/150\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.0551 - accuracy: 0.6544\n",
            "Epoch 139/150\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.0551 - accuracy: 0.6530\n",
            "Epoch 140/150\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.0551 - accuracy: 0.6516\n",
            "Epoch 141/150\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.0551 - accuracy: 0.6544\n",
            "Epoch 142/150\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.0551 - accuracy: 0.6530\n",
            "Epoch 143/150\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 0.0551 - accuracy: 0.6530\n",
            "Epoch 144/150\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.0551 - accuracy: 0.6516\n",
            "Epoch 145/150\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.0551 - accuracy: 0.6530\n",
            "Epoch 146/150\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.0551 - accuracy: 0.6530\n",
            "Epoch 147/150\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.0551 - accuracy: 0.6488\n",
            "Epoch 148/150\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.0551 - accuracy: 0.6502\n",
            "Epoch 149/150\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 0.0551 - accuracy: 0.6516\n",
            "Epoch 150/150\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.0551 - accuracy: 0.6516\n",
            "6/6 [==============================] - 0s 2ms/step\n",
            "Test Accuracy: 0.6460674157303371\n",
            "Optimized Hyperparameters\n",
            "Number of Units in Each Hidden Layer: [8, 8, 8, 16]\n",
            "Activation Function for Each Hidden Layer: ['sigmoid', 'relu', 'tanh', 'relu']\n",
            "Learning Rate: 0.00012780021378211076\n",
            "Epochs: 150\n",
            "Confusion Matrix:\n",
            "[[107   4   0]\n",
            " [ 55   8   0]\n",
            " [  4   0   0]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "lznCI5y130vo"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
